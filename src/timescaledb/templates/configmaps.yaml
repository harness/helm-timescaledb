apiVersion: v1
kind: ConfigMap
metadata:
  name: timescaledb-init
  namespace: {{ .Release.Namespace }}
  annotations:
    "helm.sh/hook": pre-install
    "helm.sh/hook-weight": "-2"
data:
  on_start: |
    #!/bin/bash

    # This script should only run on the master instance, Patroni
    # passes on the role in the second parameter
    echo "Running timescaledb-init"
    [ "$2" != "master" ] && exit 0

    echo "SELECT 'CREATE DATABASE harness' WHERE NOT EXISTS (SELECT FROM pg_database WHERE datname = 'harness')\gexec" | psql

    echo "SELECT 'CREATE DATABASE harnessti' WHERE NOT EXISTS (SELECT FROM pg_database WHERE datname = 'harnessti')\gexec" | psql

---

apiVersion: v1
kind: ConfigMap
metadata:
  name: timescaledb-single-chart-patroni
  namespace: {{ .Release.Namespace }}
  labels:
    app: timescaledb-single-chart
    chart: timescaledb-single-0.5.5
    release: timescaledb-single-chart
    heritage: Tiller
    cluster-name: timescaledb-single-chart
data:
  patroni.yaml: |
    bootstrap:
      dcs:
        loop_wait: 10
        maximum_lag_on_failover: 33554432
        postgresql:
          parameters:
            archive_command: /etc/timescaledb/scripts/pgbackrest_archive.sh %p
            archive_mode: "on"
            archive_timeout: 1800s
            autovacuum_analyze_scale_factor: 0.02
            autovacuum_max_workers: 10
            autovacuum_vacuum_scale_factor: 0.05
            hot_standby: "on"
            log_autovacuum_min_duration: 0
            log_checkpoints: "on"
            log_connections: "on"
            log_disconnections: "on"
            log_line_prefix: '%t [%p]: [%c-%l] %u@%d,app=%a [%e] '
            log_lock_waits: "on"
            log_min_duration_statement: 1s
            log_statement: ddl
            max_connections: 100
            max_prepared_transactions: 150
            shared_preload_libraries: timescaledb,pg_stat_statements
            ssl: "on"
            ssl_cert_file: /etc/certificate/tls.crt
            ssl_key_file: /etc/certificate/tls.key
            tcp_keepalives_idle: 900
            tcp_keepalives_interval: 100
            temp_file_limit: 1GB
            timescaledb.passfile: ../.pgpass
            unix_socket_directories: /var/run/postgresql
            unix_socket_permissions: "0750"
            wal_level: hot_standby
            wal_log_hints: "on"
          use_pg_rewind: true
          use_slots: true
        retry_timeout: 10
        ttl: 30
      method: restore_or_initdb
      post_init: /etc/timescaledb/scripts/post_init.sh
      restore_or_initdb:
        command: |
          /etc/timescaledb/scripts/restore_or_initdb.sh --encoding=UTF8 --locale=C.UTF-8
        keep_existing_recovery_conf: true
    kubernetes:
      ports:
      - name: postgresql
        port: 5432
        targetPort: 5432
      role_label: role
      scope_label: cluster-name
      use_endpoints: true
    log:
      level: WARNING
    postgresql:
      authentication:
        replication:
          username: standby
        superuser:
          username: postgres
      basebackup:
      - waldir: /var/lib/postgresql/wal/pg_wal
      callbacks:
        on_reload: /etc/timescaledb/scripts/patroni_callback.sh
        on_restart: /etc/timescaledb/scripts/patroni_callback.sh
        on_role_change: /etc/timescaledb/scripts/patroni_callback.sh
        on_start: /etc/timescaledb/scripts/patroni_callback.sh
        on_stop: /etc/timescaledb/scripts/patroni_callback.sh
      create_replica_methods:
      - pgbackrest
      - basebackup
      listen: 0.0.0.0:5432
      pg_hba:
      - hostnossl all,replication all                all                reject
      - local     all             all                                   peer
      - hostssl   all             all                127.0.0.1/32       md5
      - hostssl   all             all                ::1/128            md5
      - hostssl   replication     standby            all                md5
      - hostssl   all             all                all                md5
      pgbackrest:
        command: /etc/timescaledb/scripts/pgbackrest_restore.sh
        keep_data: true
        no_master: 1
        no_params: true
      recovery_conf:
        restore_command: /etc/timescaledb/scripts/pgbackrest_archive_get.sh %f "%p"
      use_unix_socket: true
    restapi:
      listen: 0.0.0.0:8008

---

apiVersion: v1
kind: ConfigMap
metadata:
  name: timescaledb-single-chart-scripts
  namespace: {{ .Release.Namespace }}
  labels:
    app: timescaledb-single-chart
    chart: timescaledb-single-0.5.5
    release: timescaledb-single-chart
    heritage: Tiller
    cluster-name: timescaledb-single-chart
data:
  # If no backup is configured, archive_command would normally fail. A failing archive_command on a cluster
  # is going to cause WAL to be kept around forever, meaning we'll fill up Volumes we have quite quickly.
  #
  # Therefore, if the backup is disabled, we always return exitcode 0 when archiving
  pgbackrest_archive.sh: |
    #!/bin/bash
    PGBACKREST_BACKUP_ENABLED=0
    [ "${PGBACKREST_BACKUP_ENABLED}" == "0" ] && exit 0

    source "${HOME}/.pgbackrest_environment"
    exec pgbackrest --stanza=poddb archive-push $1
  pgbackrest_archive_get.sh: |
    #!/bin/bash
    PGBACKREST_BACKUP_ENABLED=0
    [ "${PGBACKREST_BACKUP_ENABLED}" == "0" ] && exit 1

    source "${HOME}/.pgbackrest_environment"
    exec pgbackrest --stanza=poddb archive-get ${1} "${2}"
  pgbackrest_bootstrap.sh: |
    #!/bin/bash
    set -e

    function log {
        echo "$(date '+%Y-%m-%d %H:%M:%S') - bootstrap - $1"
    }

    while ! pg_isready -q; do
        log "Waiting for PostgreSQL to become available"
        sleep 3
    done

    # If we are the primary, we want to create/validate the backup stanza
    if [ "$(psql -c "SELECT pg_is_in_recovery()::text" -AtXq)" == "false" ]; then
        pgbackrest check || {
            log "Creating pgBackrest stanza"
            pgbackrest --stanza=poddb stanza-create --log-level-stderr=info || exit 1
        }
    fi

    log "Starting pgBackrest api to listen for backup requests"
    exec python3 /scripts/pgbackrest-rest.py --stanza=poddb --loglevel=debug
  pgbackrest_restore.sh: |
    #!/bin/bash
    PGBACKREST_BACKUP_ENABLED=0
    [ "${PGBACKREST_BACKUP_ENABLED}" == "0" ] && exit 1

    source "${HOME}/.pod_environment"

    PGDATA="/var/lib/postgresql/data"
    WALDIR="/var/lib/postgresql/wal/pg_wal"

    # A missing PGDATA points to Patroni removing a botched PGDATA, or manual
    # intervention. In this scenario, we need to recreate the DATA and WALDIRs
    # to keep pgBackRest happy
    [ -d "${PGDATA}" ] || install -o postgres -g postgres -d -m 0700 "${PGDATA}"
    [ -d "${WALDIR}" ] || install -o postgres -g postgres -d -m 0700 "${WALDIR}"

    pgbackrest --stanza=poddb --force --delta --log-level-console=detail restore
  restore_or_initdb.sh: |
    #!/bin/bash

    source "${HOME}/.pod_environment"

    function log {
      echo "$(date '+%Y-%m-%d %H:%M:%S') - restore_or_initdb - $1"
    }

    PGDATA="/var/lib/postgresql/data"
    WALDIR="/var/lib/postgresql/wal/pg_wal"

    # Patroni attaches --scope and --datadir to the arguments, we need to strip them off as
    # initdb has no business with these parameters
    initdb_args=""
    for value in "$@"
    do
      [[ $value == --scope* ]] || [[ $value == --datadir* ]] || initdb_args="${initdb_args} $value"
    done

    log "Invoking initdb"
    initdb --auth-local=peer --auth-host=md5 --pgdata="${PGDATA}" --waldir="${WALDIR}" ${initdb_args}
    echo "include_if_exists = '/var/run/postgresql/timescaledb.conf'" >> "${PGDATA}/postgresql.conf"

  post_init.sh: |
    #!/bin/bash
    PGBACKREST_BACKUP_ENABLED=0

    source "${HOME}/.pod_environment"

    function log {
        echo "$(date '+%Y-%m-%d %H:%M:%S') - post_init - $1"
    }

    log "Creating extension TimescaleDB in template1 and postgres databases"
    psql -d "$URL" <<__SQL__
      \connect template1
      -- As we're still only initializing, we cannot have synchronous_commit enabled just yet.
      SET synchronous_commit to 'off';
      CREATE EXTENSION timescaledb;

      \connect postgres
      SET synchronous_commit to 'off';
      CREATE EXTENSION timescaledb;
    __SQL__

    TABLESPACES=""
    for tablespace in $TABLESPACES
    do
      log "Creating tablespace ${tablespace}"
      tablespacedir="/var/lib/postgresql/tablespaces/${tablespace}/data"
      psql -d "$URL" --set tablespace="${tablespace}" --set directory="${tablespacedir}" --set ON_ERROR_STOP=1 <<__SQL__
        SET synchronous_commit to 'off';
        CREATE TABLESPACE :"tablespace" LOCATION :'directory';
    __SQL__
    done

    if [ "${PGBACKREST_BACKUP_ENABLED}" == "1" ]; then
      log "Waiting for pgBackRest API to become responsive"
      while sleep 1; do
          if [ $SECONDS -gt 10 ]; then
              log "pgBackRest API did not respond within $SECONDS seconds, will not trigger a backup"
              exit 0
          fi
          timeout 1 bash -c "echo > /dev/tcp/localhost/8081" 2>/dev/null && break
      done

      log "Triggering pgBackRest backup"
      curl -i -X POST http://localhost:8081/backups
    fi

    # We always exit 0 this script, otherwise the database initialization fails.
    exit 0
  patroni_callback.sh: |
    #!/bin/bash
    set -e

    source "${HOME}/.pod_environment"

    for suffix in "$1" all
    do
      CALLBACK="/etc/timescaledb/callbacks/${suffix}"
      if [ -f "${CALLBACK}" ]
      then
        "${CALLBACK}" $@
      fi
    done

  lifecycle_preStop.psql: |
    \pset pager off
    \set ON_ERROR_STOP true
    \set hostname `hostname`
    \set dsn_fmt 'user=postgres host=%s application_name=lifecycle:preStop@%s connect_timeout=5 options=''-c log_min_duration_statement=0'''

    SELECT
        pg_is_in_recovery() AS in_recovery,
        format(:'dsn_fmt', patroni_scope,                       :'hostname') AS primary_dsn,
        format(:'dsn_fmt', '/var/run/postgresql', :'hostname') AS local_dsn
    FROM
        current_setting('cluster_name') AS cs(patroni_scope)
    \gset

    \timing on
    \set ECHO queries

    -- There should be a CHECKPOINT at the primary
    \if :in_recovery
        \connect :"primary_dsn"
        CHECKPOINT;
    \endif

    -- There should also be a CHECKPOINT locally,
    -- for the primary, this may mean we do a double checkpoint,
    -- but the second one would be cheap anyway, so we leave that as is
    \connect :"local_dsn"
    SELECT 'Issuing checkpoint';
    CHECKPOINT;

    \if :in_recovery
        SELECT 'We are a replica: Successfully invoked checkpoints at the primary and locally.';
    \else
        SELECT 'We are a primary: Successfully invoked checkpoints, now issuing a switchover.';
        \! curl -s http://localhost:8008/switchover -XPOST -d '{"leader": "$(hostname)"}'
    \endif
